# DESCRIPTION: A simple three-state pomdp.  In state s<n>, you want to
# perform action a<n>.  a<n> gives you 3 if you're right, 0 if you're
# wrong, no information.  obs always gives you 1 and perfect information
# about what state you're in, so you use it when you're not sure.  The
# transition matrix is the identity but with small off-diagonal
# probabilities so that uncertainty increases some over time.
#
# Copyright (c) 2002, Trey Smith.  All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:
#
# * The software may not be sold or incorporated into a commercial
#   product without specific prior written permission.
# * The above copyright notice and this permission notice shall be
#   included in all copies or substantial portions of the software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

discount: 0.9
values: reward
states: s0 s1 s2
actions: a0 a1 a2 obs
observations: p0 p1 p2

start: 
0.3333333333 0.33333333333 0.33333333333

T:a0
0.8 0.1 0.1
0.1 0.8 0.1
0.1 0.1 0.8

T:a1
0.8 0.1 0.1
0.1 0.8 0.1
0.1 0.1 0.8

T:a2
0.8 0.1 0.1
0.1 0.8 0.1
0.1 0.1 0.8

T:obs
0.8 0.1 0.1
0.1 0.8 0.1
0.1 0.1 0.8

O:a0
1 0 0
1 0 0
1 0 0

O:a1
1 0 0
1 0 0
1 0 0

O:a2
1 0 0
1 0 0
1 0 0

O:obs
1 0 0
0 1 0
0 0 1

R:a0     : s0    : * : * 3
R:a0     : s1    : * : * 0
R:a0     : s2    : * : * 0

R:a1     : s0    : * : * 0
R:a1     : s1    : * : * 3
R:a1     : s2    : * : * 0

R:a2     : s0    : * : * 0
R:a2     : s1    : * : * 0
R:a2     : s2    : * : * 3

R:obs    : *     : * : * 1
